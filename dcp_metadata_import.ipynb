{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "from numpy import nan\n",
    "\n",
    "from tier1_to_dcp_dict import tier1_to_dcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_id = 'bcb61471-2a44-4d00-a0af-ff085512674c'\n",
    "dataset_id = '0b75c598-0893-4216-afe8-5414cab7739d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_metadata = pd.read_csv(f\"metadata/{collection_id}_{dataset_id}_study_metadata.csv\", header=None).T\n",
    "study_metadata.columns = study_metadata.iloc[0]\n",
    "study_metadata.drop(0, axis=0, inplace=True)\n",
    "sample_metadata = pd.read_csv(f\"metadata/{collection_id}_{dataset_id}_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_metadata = pd.read_csv('example/ImmuneLandscapeccRCC_metadata_30-01-2023_tier1_obs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hca_template_url = 'https://github.com/ebi-ait/geo_to_hca/raw/master/template/hca_template.xlsx'\n",
    "dcp_spreadsheet = pd.read_excel(hca_template_url, sheet_name=None, skiprows= [0,1,2,4])\n",
    "\n",
    "# save the 4-row header of the original spreadsheet with programmatic name as column names\n",
    "dcp_headers = pd.read_excel(hca_template_url, sheet_name=None, header=None)\n",
    "for tab in dcp_headers:\n",
    "    dcp_headers[tab].rename(columns=dcp_headers[tab].iloc[3], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'doi' in sample_metadata and len(set(sample_metadata['doi'])) == 1:\n",
    "    dcp_spreadsheet['Project - Publications'] = pd.DataFrame({key: \\\n",
    "        (study_metadata['doi'].tolist() if key.endswith(\"doi\") \\\n",
    "            else [nan]) \\\n",
    "            for key in dcp_spreadsheet['Project - Publications'].keys()})\n",
    "\n",
    "if 'institute' in sample_metadata:\n",
    "    # TODO add institute per sample\n",
    "    if len(set(sample_metadata['institute'])) == 1:\n",
    "        dcp_spreadsheet['Cell suspension']['process.process_core.location'] = sample_metadata['institute'][0]\n",
    "if 'title' in sample_metadata:\n",
    "    if len(set(sample_metadata['title'])) != 1:\n",
    "        print(f\"We have multiple titles {set(sample_metadata['title'])}\")\n",
    "    dcp_spreadsheet['Project'] = pd.DataFrame({key: \\\n",
    "    (sample_metadata['title'][0] if key.endswith(\"project_title\") \\\n",
    "        else [nan]) \\\n",
    "        for key in dcp_spreadsheet['Project'].keys()})\n",
    "if 'study_pi' in  sample_metadata and \\\n",
    "    'institute' in sample_metadata:\n",
    "    #Â TODO add fix for multiple institutes per sample\n",
    "    if len(set(sample_metadata['study_pi'])) == 1 and \\\n",
    "        len(set(sample_metadata['institute'])) == 1:\n",
    "        study_pi_dict = {\n",
    "            'project.contributors.name': sample_metadata['study_pi'][0], \n",
    "            'project.contributors.institution': sample_metadata['institute'][0],\n",
    "            'project.contributors.corresponding_contributor': 'yes'\n",
    "            }\n",
    "        study_pi_dict.update({\n",
    "            key: nan for key in dcp_spreadsheet['Project - Contributors'].keys() if key not in study_pi_dict.keys()\n",
    "        })\n",
    "        dcp_spreadsheet['Project - Contributors'] = pd.DataFrame(study_pi_dict, index=[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sample_collection_relative_time_point' in sample_metadata:\n",
    "    number_pattern = '([\\\\d]+[.|\\\\,]?\\\\d?)'\n",
    "    sample_metadata['specimen_from_organism.biomaterial_core.timecourse.value'] = \\\n",
    "        sample_metadata['sample_collection_relative_time_point'].str.extract(number_pattern, expand=False)\n",
    "    sample_metadata.loc[sample_metadata['sample_collection_relative_time_point'].notna(), 'specimen_from_organism.biomaterial_core.timecourse.relevance'] = 'relative time of collection'\n",
    "    time_units_pattern = r'(hour|day|week|month|year)'\n",
    "    sample_metadata['specimen_from_organism.biomaterial_core.timecourse.unit.text'] = \\\n",
    "        sample_metadata['sample_collection_relative_time_point'].str.extract(time_units_pattern, expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'organism_ontology_term_id' in sample_metadata:\n",
    "    sample_metadata['organism_ontology_term_id'] = sample_metadata['organism_ontology_term_id'].str.removeprefix('NCBITaxon:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_ontology_dict = {\n",
    "    'sex_ontology_term_id':\n",
    "        {\n",
    "            'PATO:0000383': 'female',\n",
    "            'PATO:0000384': 'male'\n",
    "        }           \n",
    "}\n",
    "if 'sex_ontology_term_id' in sample_metadata:\n",
    "    sample_metadata.replace(sex_ontology_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sample_source' in sample_metadata:\n",
    "    sample_metadata['specimen_from_organism.transplant_organ'] = sample_metadata.apply(lambda x: 'yes' if x['sample_source'] == 'organ_donor' else 'no', axis=1)\n",
    "    if any((sample_metadata['sample_source'] == 'postmortem donor') & (sample_metadata['manner_of_death'] == 'not applicable')) or \\\n",
    "       any((sample_metadata['sample_source'] != 'postmortem donor') & (sample_metadata['manner_of_death'] != 'not applicable')):\n",
    "        print(f'Conflicting metadata {sample_metadata.loc[(sample_metadata['sample_source'] == 'postmortem donor') & (sample_metadata['manner_of_death'] == 'not applicable'), ['sample_source', 'manner_of_death']]}')\n",
    "        print(f'Conflicting metadata {sample_metadata.loc[(sample_metadata['sample_source'] != 'postmortem donor') & (sample_metadata['manner_of_death'] != 'not applicable'), ['sample_source', 'manner_of_death']]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hardy_scale = [0, 1, 2, 3, 4, '0', '1', '2', '3', '4']\n",
    "manner_of_death_is_living_dict = {n: 'no' for n in hardy_scale}\n",
    "manner_of_death_is_living_dict.update({'unknown': 'no', 'not applicable': 'yes'})\n",
    "manner_of_death_is_living_dict = {'donor_organism.is_living': manner_of_death_is_living_dict}\n",
    "\n",
    "if 'manner_of_death' in sample_metadata:\n",
    "    sample_metadata['donor_organism.is_living'] = sample_metadata['manner_of_death']\n",
    "    sample_metadata.replace(manner_of_death_is_living_dict, inplace=True)\n",
    "    sample_metadata['manner_of_death'] = sample_metadata.apply(lambda x: x['manner_of_death'] if x['manner_of_death'] in hardy_scale else nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sampled_site_condition' in sample_metadata:\n",
    "    # if sampled_site_condition is adjacent, we fill adjacent_diseases with disease_ontology_term_id\n",
    "    # if diseased: known_diseases = disease_ontology_term_id and adjacent = nan\n",
    "    # if healthy: known_diseases = disease_ontology_term_id or PATO:0000461 and adjacent = nan\n",
    "    def sampled_site_to_known_diseases(row):\n",
    "        if row['sampled_site_condition'] == 'adjacent' and 'disease_ontology_term_id' in row:\n",
    "            return ['PATO:0000461', row['disease_ontology_term_id']]\n",
    "            if row['disease_ontology_term_id'] != 'PATO:0000461':\n",
    "                print(f'Conflicting metadata {row[['sampled_site_condition', 'disease_ontology_term_id']]}')\n",
    "        elif row['sampled_site_condition'] in ['healthy', 'diseased'] and 'disease_ontology_term_id' in row:\n",
    "            return [row['disease_ontology_term_id'], nan]\n",
    "        elif row['sampled_site_condition'] == 'healthy':\n",
    "            return ['PATO:0000461', nan]\n",
    "        else:\n",
    "            return [nan, nan]\n",
    "\n",
    "    sample_metadata[['specimen_from_organism.diseases.ontology', 'specimen_from_organism.adjacent_diseases.ontology']] = \\\n",
    "        sample_metadata.apply(sampled_site_to_known_diseases, axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we expect this to become an enum, when it would be easier to extract\n",
    "# for now we extract the numbers as in the example pattern\n",
    "if 'alignment_software' in sample_metadata:\n",
    "    sample_metadata[['analysis_protocol.alignment_software', 'analysis_protocol.alignment_software_version']] = \\\n",
    "        sample_metadata['alignment_software'].str.extract(r'([\\w\\s]+)\\s(v?[\\d\\.]+)')\n",
    "    no_version = ~sample_metadata['alignment_software'].str.match(r'.*v?[\\d\\.]+')\n",
    "    sample_metadata.loc[no_version, 'analysis_protocol.alignment_software'] = \\\n",
    "            sample_metadata.loc[no_version, 'alignment_software']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'library_sequencing_run' in sample_metadata:\n",
    "    insdc_run_pattern = r'^[D|E|S]RR[0-9]+(\\|\\|[D|E|S]RR[0-9]+)*$'\n",
    "    separator = sample_metadata['library_sequencing_run'].str.extract(r'([^D|E|S|R|0-9]+)', expand=False).dropna().unique()\n",
    "    if len(separator) > 0:\n",
    "        sample_metadata['library_sequencing_run'] = sample_metadata['library_sequencing_run'].str.replace(separator[0], '||')\n",
    "    if not sample_metadata['library_sequencing_run'].str.match(insdc_run_pattern).all():\n",
    "        print('Following library sequencing run IDs does not match the INSDC pattern')\n",
    "        display(sample_metadata.loc[~sample_metadata['library_sequencing_run'].str.match(insdc_run_pattern), ['sample_id', 'library_id', 'library_sequencing_run']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcp_flat = sample_metadata.rename(columns=tier1_to_dcp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tab in dcp_spreadsheet:\n",
    "    keys_union = [key for key in dcp_spreadsheet[tab].keys() if key in dcp_flat.keys()]\n",
    "    # if tab contains only the input biomaterial name, then skip the tab\n",
    "    if (len(keys_union) == 1) and (tab.lower().replace(\" \", \"_\") != keys_union[0].split(\".\")[0]):\n",
    "        continue\n",
    "    # collapse arrays in duplicated columns\n",
    "    if any(dcp_flat[keys_union].columns.duplicated()):\n",
    "        for dub_cols in set(dcp_flat[keys_union].columns[dcp_flat[keys_union].columns.duplicated()]):\n",
    "            df = dcp_flat[dub_cols]\n",
    "            dcp_flat.drop(columns=dub_cols, inplace=True)\n",
    "            dcp_flat[dub_cols] = df[dub_cols].apply(lambda x: '||'.join(x.dropna().astype(str)),axis=1)\n",
    "\n",
    "    # merge the two dataframes\n",
    "    dcp_spreadsheet[tab] = pd.concat([dcp_spreadsheet[tab],dcp_flat[keys_union]])\n",
    "    dcp_spreadsheet[tab] = dcp_spreadsheet[tab].dropna(how='all').drop_duplicates()\n",
    "\n",
    "    # generate a unique protocol_id\n",
    "    if tab.endswith('protocol') and keys_union:\n",
    "        dcp_spreadsheet[tab] = dcp_spreadsheet[tab].drop_duplicates()\n",
    "        # there should be only 1 protocol_id in each protocol tab. we need a series to replace spaces\n",
    "        protocol_id_col = [col for col in dcp_spreadsheet[tab].columns if col.endswith('protocol_core.protocol_id')][0]\n",
    "        dcp_spreadsheet[tab][protocol_id_col] = [tab.lower().replace(\" \",\"_\") + \"_\" + str(n + 1) for n in range(len(dcp_spreadsheet[tab]))]\n",
    "\n",
    "    if tab == 'Project':\n",
    "        dcp_spreadsheet[tab] = dcp_spreadsheet[tab].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should have 1 only Analysis file with all the CS merged\n",
    "\n",
    "def collapse_values(series):\n",
    "    return \"||\".join(series.unique().astype(str))\n",
    "\n",
    "dcp_spreadsheet['Analysis file']['analysis_file.file_core.file_name'] = f'{collection_id}_{dataset_id}.h5ad'\n",
    "dcp_spreadsheet['Analysis file']['analysis_file.file_core.content_description.text'] = 'count matrix'\n",
    "dcp_spreadsheet['Analysis file']['analysis_file.file_core.file_source'] = 'CxG'\n",
    "dcp_spreadsheet['Analysis file']['analysis_file.file_core.format'] = 'h5ad'\n",
    "\n",
    "\n",
    "adata_protocol_ids = {\n",
    "    'Library preparation protocol': 'library_preparation_protocol.protocol_core.protocol_id',\n",
    "    'Sequencing protocol': 'sequencing_protocol.protocol_core.protocol_id',\n",
    "    'Analysis protocol': 'analysis_protocol.protocol_core.protocol_id'\n",
    "}\n",
    "\n",
    "for tab, id in adata_protocol_ids.items():\n",
    "    dcp_spreadsheet['Analysis file'][id] = \\\n",
    "    collapse_values(\\\n",
    "        dcp_spreadsheet[tab][id]\n",
    "    )\n",
    "\n",
    "\n",
    "dcp_spreadsheet['Analysis file'] = dcp_spreadsheet['Analysis file']\\\n",
    "    .groupby('analysis_file.file_core.file_name')\\\n",
    "    .agg(collapse_values)\\\n",
    "    .reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project\n",
      "Project - Contributors\n",
      "Donor organism\n",
      "Specimen from organism\n",
      "Cell suspension\n",
      "Sequence file\n",
      "Collection protocol\n",
      "Enrichment protocol\n",
      "Library preparation protocol\n",
      "Sequencing protocol\n",
      "Analysis file\n",
      "Analysis protocol\n"
     ]
    }
   ],
   "source": [
    "with pd.ExcelWriter(f\"metadata/{collection_id}_{dataset_id}_dcp.xlsx\") as writer:\n",
    "    for tab in dcp_spreadsheet:\n",
    "        if not dcp_spreadsheet[tab].empty:\n",
    "            print(tab)\n",
    "            pd.concat([dcp_headers[tab], dcp_spreadsheet[tab]]).to_excel(writer, sheet_name=tab, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_file.file_core.file_name</th>\n",
       "      <th>analysis_file.file_core.format</th>\n",
       "      <th>analysis_file.file_core.content_description.text</th>\n",
       "      <th>analysis_file.file_core.content_description.ontology</th>\n",
       "      <th>analysis_file.file_core.content_description.ontology_label</th>\n",
       "      <th>analysis_file.file_core.checksum</th>\n",
       "      <th>analysis_file.file_core.file_source</th>\n",
       "      <th>analysis_file.matrix_cell_count</th>\n",
       "      <th>analysis_file.genome_assembly_version</th>\n",
       "      <th>analysis_file.genome_patch_version</th>\n",
       "      <th>...</th>\n",
       "      <th>process.end_time</th>\n",
       "      <th>process.length_of_time</th>\n",
       "      <th>process.length_of_time_unit.text</th>\n",
       "      <th>process.length_of_time_unit.ontology</th>\n",
       "      <th>process.length_of_time_unit.ontology_label</th>\n",
       "      <th>process.type.text</th>\n",
       "      <th>process.type.ontology</th>\n",
       "      <th>process.type.ontology_label</th>\n",
       "      <th>process.deviation_from_protocol</th>\n",
       "      <th>process.insdc_experiment.insdc_experiment_accession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bcb61471-2a44-4d00-a0af-ff085512674c_0b75c598-...</td>\n",
       "      <td>h5ad</td>\n",
       "      <td>count matrix</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>CxG</td>\n",
       "      <td>nan</td>\n",
       "      <td>GRCh37</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   analysis_file.file_core.file_name  \\\n",
       "0  bcb61471-2a44-4d00-a0af-ff085512674c_0b75c598-...   \n",
       "\n",
       "  analysis_file.file_core.format  \\\n",
       "0                           h5ad   \n",
       "\n",
       "  analysis_file.file_core.content_description.text  \\\n",
       "0                                     count matrix   \n",
       "\n",
       "  analysis_file.file_core.content_description.ontology  \\\n",
       "0                                                nan     \n",
       "\n",
       "  analysis_file.file_core.content_description.ontology_label  \\\n",
       "0                                                nan           \n",
       "\n",
       "  analysis_file.file_core.checksum analysis_file.file_core.file_source  \\\n",
       "0                              nan                                 CxG   \n",
       "\n",
       "  analysis_file.matrix_cell_count analysis_file.genome_assembly_version  \\\n",
       "0                             nan                                GRCh37   \n",
       "\n",
       "  analysis_file.genome_patch_version  ... process.end_time  \\\n",
       "0                                nan  ...              nan   \n",
       "\n",
       "  process.length_of_time process.length_of_time_unit.text  \\\n",
       "0                    nan                              nan   \n",
       "\n",
       "  process.length_of_time_unit.ontology  \\\n",
       "0                                  nan   \n",
       "\n",
       "  process.length_of_time_unit.ontology_label process.type.text  \\\n",
       "0                                        nan               nan   \n",
       "\n",
       "  process.type.ontology process.type.ontology_label  \\\n",
       "0                   nan                         nan   \n",
       "\n",
       "  process.deviation_from_protocol  \\\n",
       "0                             nan   \n",
       "\n",
       "  process.insdc_experiment.insdc_experiment_accession  \n",
       "0                                                nan   \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcp_spreadsheet['Analysis file']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
