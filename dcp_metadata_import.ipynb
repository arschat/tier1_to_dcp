{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "from numpy import nan\n",
    "\n",
    "from tier1_to_dcp_dict import tier1_to_dcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_id = 'bcb61471-2a44-4d00-a0af-ff085512674c'\n",
    "dataset_id = '0b75c598-0893-4216-afe8-5414cab7739d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_metadata = pd.read_csv(f\"metadata/{collection_id}_{dataset_id}_study_metadata.csv\", header=None).T\n",
    "study_metadata.columns = study_metadata.iloc[0]\n",
    "study_metadata.drop(0, axis=0, inplace=True)\n",
    "sample_metadata = pd.read_csv(f\"metadata/{collection_id}_{dataset_id}_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_metadata = pd.read_csv('example/ImmuneLandscapeccRCC_metadata_30-01-2023_tier1_obs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hca_template_url = 'https://github.com/ebi-ait/geo_to_hca/raw/master/template/hca_template.xlsx'\n",
    "dcp_spreadsheet = pd.read_excel(hca_template_url, sheet_name=None, skiprows= [0,1,2,4])\n",
    "\n",
    "# save the 4-row header of the original spreadsheet with programmatic name as column names\n",
    "dcp_headers = pd.read_excel(hca_template_url, sheet_name=None, header=None)\n",
    "for tab in dcp_headers:\n",
    "    dcp_headers[tab].rename(columns=dcp_headers[tab].iloc[3], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'doi' in sample_metadata and len(set(sample_metadata['doi'])) == 1:\n",
    "    dcp_spreadsheet['Project - Publications'] = pd.DataFrame({key: \\\n",
    "        (study_metadata['doi'].tolist() if key.endswith(\"doi\") \\\n",
    "            else [nan]) \\\n",
    "            for key in dcp_spreadsheet['Project - Publications'].keys()})\n",
    "\n",
    "if 'institute' in sample_metadata:\n",
    "    # TODO add institute per sample\n",
    "    if len(set(sample_metadata['institute'])) == 1:\n",
    "        dcp_spreadsheet['Cell suspension']['process.process_core.location'] = sample_metadata['institute'][0]\n",
    "if 'title' in sample_metadata:\n",
    "    if len(set(sample_metadata['title'])) != 1:\n",
    "        print(f\"We have multiple titles {set(sample_metadata['title'])}\")\n",
    "    dcp_spreadsheet['Project'] = pd.DataFrame({key: \\\n",
    "    (sample_metadata['title'][0] if key.endswith(\"project_title\") \\\n",
    "        else [nan]) \\\n",
    "        for key in dcp_spreadsheet['Project'].keys()})\n",
    "if 'study_pi' in  sample_metadata.columns and \\\n",
    "    'institute' in sample_metadata:\n",
    "    #Â TODO add fix for multiple institutes per sample\n",
    "    if len(set(sample_metadata['study_pi'])) == 1 and \\\n",
    "        len(set(sample_metadata['institute'])) == 1:\n",
    "        study_pi_dict = {\n",
    "            'project.contributors.name': sample_metadata['study_pi'][0], \n",
    "            'project.contributors.institution': sample_metadata['institute'][0],\n",
    "            'project.contributors.corresponding_contributor': 'yes'\n",
    "            }\n",
    "        study_pi_dict.update({\n",
    "            key: nan for key in dcp_spreadsheet['Project - Contributors'].keys() if key not in study_pi_dict.keys()\n",
    "        })\n",
    "        dcp_spreadsheet['Project - Contributors'] = pd.DataFrame(study_pi_dict, index=[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sample_collection_relative_time_point' in sample_metadata:\n",
    "    number_pattern = '([\\\\d]+[.|\\\\,]?\\\\d?)'\n",
    "    sample_metadata['specimen_from_organism.biomaterial_core.timecourse.value'] = \\\n",
    "        sample_metadata['sample_collection_relative_time_point'].str.extract(number_pattern, expand=False)\n",
    "    sample_metadata.loc[sample_metadata['sample_collection_relative_time_point'].notna(), 'specimen_from_organism.biomaterial_core.timecourse.relevance'] = 'relative time of collection'\n",
    "    time_units_pattern = r'(hour|day|week|month|year)'\n",
    "    sample_metadata['specimen_from_organism.biomaterial_core.timecourse.unit.text'] = \\\n",
    "        sample_metadata['sample_collection_relative_time_point'].str.extract(time_units_pattern, expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'organism_ontology_term_id' in sample_metadata:\n",
    "    sample_metadata['donor_organism.biomaterial_core.ncbi_taxon_id'] = sample_metadata['organism_ontology_term_id'].str.removeprefix('NCBITaxon:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_ontology_dict = {\n",
    "    'donor_organism.sex':\n",
    "        {\n",
    "            'PATO:0000383': 'female',\n",
    "            'PATO:0000384': 'male'\n",
    "        }           \n",
    "}\n",
    "if 'sex_ontology_term_id' in sample_metadata:\n",
    "    sample_metadata['donor_organism.sex'] = sample_metadata['sex_ontology_term_id']\n",
    "    sample_metadata.replace(sex_ontology_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hardy_scale = [0, 1, 2, 3, 4, '0', '1', '2', '3', '4']\n",
    "manner_of_death_is_living_dict = {n: 'no' for n in hardy_scale}\n",
    "manner_of_death_is_living_dict.update({'unknown': 'no', 'not applicable': 'yes'})\n",
    "manner_of_death_is_living_dict = {'donor_organism.is_living': manner_of_death_is_living_dict}\n",
    "\n",
    "if 'manner_of_death' in sample_metadata:\n",
    "    sample_metadata['donor_organism.death.hardy_scale'] = sample_metadata.apply(lambda x: x['manner_of_death'] if x['manner_of_death'] in hardy_scale else nan, axis=1)\n",
    "    sample_metadata['donor_organism.is_living'] = sample_metadata['manner_of_death']\n",
    "    sample_metadata.replace(manner_of_death_is_living_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sample_source' in sample_metadata:\n",
    "    sample_metadata['specimen_from_organism.transplant_organ'] = sample_metadata.apply(lambda x: 'yes' if x['sample_source'] == 'organ_donor' else 'no', axis=1)\n",
    "    if any((sample_metadata['sample_source'] == 'postmortem donor') & (sample_metadata['manner_of_death'] == 'not applicable')) or \\\n",
    "       any((sample_metadata['sample_source'] != 'postmortem donor') & (sample_metadata['manner_of_death'] != 'not applicable')):\n",
    "        print(f'Conflicting metadata {sample_metadata.loc[(sample_metadata['sample_source'] == 'postmortem donor') & (sample_metadata['manner_of_death'] == 'not applicable'), ['sample_source', 'manner_of_death']]}')\n",
    "        print(f'Conflicting metadata {sample_metadata.loc[(sample_metadata['sample_source'] != 'postmortem donor') & (sample_metadata['manner_of_death'] != 'not applicable'), ['sample_source', 'manner_of_death']]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcp_flat = sample_metadata.rename(columns=tier1_to_dcp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tab in dcp_spreadsheet:\n",
    "    keys_union = [key for key in dcp_spreadsheet[tab].keys() if key in dcp_flat.keys()]\n",
    "    # if tab contains only the input biomaterial name, then skip the tab\n",
    "    if (len(keys_union) == 1) and (tab.lower().replace(\" \", \"_\") != keys_union[0].split(\".\")[0]):\n",
    "        continue\n",
    "    # collapse arrays in duplicated columns\n",
    "    if any(dcp_flat[keys_union].columns.duplicated()):\n",
    "        for dub_cols in set(dcp_flat[keys_union].columns[dcp_flat[keys_union].columns.duplicated()]):\n",
    "            df = dcp_flat[dub_cols]\n",
    "            dcp_flat.drop(columns=dub_cols, inplace=True)\n",
    "            dcp_flat[dub_cols] = df[dub_cols].apply(lambda x: '||'.join(x.dropna().astype(str)),axis=1)\n",
    "\n",
    "    # merge the two dataframes\n",
    "    dcp_spreadsheet[tab] = pd.concat([dcp_spreadsheet[tab],dcp_flat[keys_union]])\n",
    "    dcp_spreadsheet[tab] = dcp_spreadsheet[tab].dropna(how='all').drop_duplicates()\n",
    "\n",
    "    # generate a unique protocol_id\n",
    "    if tab.endswith('protocol') and keys_union:\n",
    "        dcp_spreadsheet[tab] = dcp_spreadsheet[tab].drop_duplicates()\n",
    "        # there should be only 1 protocol_id in each protocol tab. we need a series to replace spaces\n",
    "        protocol_id_col = [col for col in dcp_spreadsheet[tab].columns if col.endswith('protocol_core.protocol_id')][0]\n",
    "        dcp_spreadsheet[tab][protocol_id_col] = [tab.lower().replace(\" \",\"_\") + \"_\" + str(n + 1) for n in range(len(dcp_spreadsheet[tab]))]\n",
    "\n",
    "    if tab == 'Project':\n",
    "        dcp_spreadsheet[tab] = dcp_spreadsheet[tab].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project\n",
      "Project - Contributors\n",
      "Donor organism\n",
      "Specimen from organism\n",
      "Cell suspension\n",
      "Sequence file\n",
      "Collection protocol\n",
      "Enrichment protocol\n",
      "Library preparation protocol\n",
      "Sequencing protocol\n",
      "Analysis file\n",
      "Analysis protocol\n"
     ]
    }
   ],
   "source": [
    "with pd.ExcelWriter(f\"metadata/{collection_id}_{dataset_id}_dcp.xlsx\") as writer:\n",
    "    for tab in dcp_spreadsheet:\n",
    "        if not dcp_spreadsheet[tab].empty:\n",
    "            print(tab)\n",
    "            pd.concat([dcp_headers[tab], dcp_spreadsheet[tab]]).to_excel(writer, sheet_name=tab, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
